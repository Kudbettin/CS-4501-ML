# 2. End-to-end ML Project

- Popular data repositories:
  - [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/index.php)
  - [Registry of Open Data on AWS](https://aws.amazon.com/fr/datasets/)
  - [List of datasets for machine learning research - Wikipedia](https://en.wikipedia.org/wiki/List_of_datasets_for_machine_learning_research)
  - [Kaggle: Your Home for Data Science](http://kaggle.com/)

## 8 Main Steps of a ML Project

### 1. Look at the big picture
- Ask the purpose of building a model -> frame your problems and objectives:
  - What do you expect, use, and benefit from this model?
  - What learning algorithm to use?
  - What performance measure to evaluate (metric)?
    - One option is **Mean Absolute Error** ($|residual|$)
      - $MAE(X,h) = \frac{1}{m}\sum_{i=1}^m|h(x^{(i)})-y^{(i)}|$
      - $m$ is the number of instances, h is the hypothesis function
    - Another option is the **Root Mean Square Error**
      - $RMSE(X,h) = \sqrt{\frac{1}{m}\sum_{i=1}^m(h(x^{(i)})-y^{(i)})^2}$
  - How much effort to be spent?

### 2. Get the data.
- Load data from a .csv file with `df = pd.read_csv(csv_path)`
- `df.head()` prints the first 5 rows in a dataframe
- `df.info()` provides you an overview of the dataframe
- `df.describe()` provides you with basic statistics
- Create train and test sets with `train_set, test_set = train_test_split(df,test_size=TEST_PROP,random_state=SEED)` from `sklearn.model_selection`

### 3. Discover and visualize the data to gain insights
- Plot a histogram with `df.hist()`
- Discover and visualize the data with `df.plot(kind=?,x=X_COL,y=Y_COL)`
- Look at correlations with `corr_matrix = df.corr()`
- Check all correlations with `df.scatter_matrix()`
- Experiment with Feature Extraction like so: `df["New feature"] = df["Feature 1"] <MATH OPERATION> df["Feature 2"]`

### 4. Prepare the data for Machine Learning algorithms (data cleaning)
- Dectect missing values `incomplete_rows = df[df.isnull().any(axis=1)]`
- Fill in missing values with `imputer = Imputer(strategy=?)` and then `arr = imputer.transform(df)`
- Process categorical inputs, possibly by encoding the categories with `cat_encoder = OneHotEncoder(sparse=False)` and then `arr = cat_encoder.fit(df_category_columns)`
- Use `Pipeline` for a sequence of transormations with `num_pipe = Pipeline([(STRATEGY 1),(STRATEGY 2),(STRATEGY 3...)])` followed by `arr = num_pipe.fit_transform(df_num_categories)`
- Combine columns with `ColumnTransformer`, similar syntax to the `Pipeline`.

### 5. Select a model and train it.
- Pick the model, not much else to be said.  Linear regressions, decision tree regressions, random forest regression, etc.
- evaluate on some test data: you can use `df.iloc[]` to select a few training instances (same syntax as lists)
- After fitting, compare against the actual values (the labels are a column in your dataframe)
- Calculate the errors with `mean_squared_error(labels,predictions)` or `mean_absolute_error(labels,predictions)`.  Both are imported from `sklearn.metrics`
- Evaluate with `cross_val_score`

### 6. Fine-tune your model
- Run a grid search on the parameters to determine the best hyperparameters.

### 7. Present your solution
- Evaluate on the test set
- Create a nice presentation with visual aids

### 8. Launch, Monitor, and Maintain
- Update the model over time with new training data
- Evaluate based on the field experts
- Ensure the quality of incoming training data
- refresh the model at a regular interval
- Backup the previous model
